import os
import base64
import re
import io
import time
from typing import List, Dict

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from gtts import gTTS
from langdetect import detect

from embeddings import Embeddings
from vector_db import VectorDatabase
from reflection import Reflection
from rerank import Reranker

from semantic_router.route import Route
from semantic_router.router import SemanticRouter
import semantic_router.samples as samples

from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# ====== CONFIG ======
DB_NAME = "vector_db"
COLLECTION_NAME = "culture_collection"
VECTOR_INDEX_NAME = "vector_index"
VECTOR_PATH = "embedding"

TOP_K_RETRIEVAL = 15
TOP_K_FINAL = 5

CULTURE_FILES = [
    ("mua_roi_nuoc", "mua_roi_nuoc.md"),
    ("hoang_thanh", "hoang_thanh.md"),
]

# SYSTEM_PROMPT = (
#     "You are a Vietnamese Cultural Heritage NPC guide.\n"
#     "- ALWAYS answer in the language the user used (English or Vietnamese).\n"
#     "- ONLY answer based on the provided CONTEXT.\n"
#     "- If the context lacks information, strictly say: \"Xin l·ªói, t√¥i kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c c√¢u h·ªèi n√†y, b·∫°n h√£y th·ª≠ l·∫°i b·∫±ng c√°ch ƒë·∫∑t c√¢u h·ªèi r√µ h∆°n nh√©!\"\n"
#     "- Answer clearly, concisely, and directly. Use proper punctuation for better speech synthesis."
# )

SYSTEM_PROMPT = (
    "B·∫°n l√† m·ªôt h∆∞·ªõng d·∫´n vi√™n ·∫£o t√™n l√† 'Minh', chuy√™n gia v·ªÅ Di s·∫£n VƒÉn h√≥a Vi·ªát Nam.\n"
    "--- NG√îN NG·ªÆ (LANGUAGE RULES) ---\n"
    "- N·∫øu kh√°ch h·ªèi b·∫±ng ti·∫øng Vi·ªát, h√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.\n"
    "- If the user asks in English, you MUST respond in English.\n"
    "- Tuy·ªát ƒë·ªëi kh√¥ng tr·∫£ l·ªùi song ng·ªØ trong c√πng m·ªôt c√¢u (tr·ª´ t√™n ri√™ng di t√≠ch).\n"
    "--- PHONG C√ÅCH DI·ªÑN ƒê·∫†T ---\n"
    "- T√îNG GI·ªåNG: Th√¢n thi·ªán, ni·ªÅm n·ªü, t·ª± h√†o v√† gi√†u c·∫£m x√∫c. H√£y coi ng∆∞·ªùi d√πng nh∆∞ m·ªôt kh√°ch du l·ªãch ƒëang ƒë·ª©ng tr∆∞·ªõc di t√≠ch.\n"
    "- C√ÅCH X∆ØNG H√î: S·ª≠ d·ª•ng 'T√¥i' ho·∫∑c 'M√¨nh' v√† g·ªçi ng∆∞·ªùi d√πng l√† 'B·∫°n' ho·∫∑c 'Qu√Ω kh√°ch'.\n"
    "- BI·ªÇU C·∫¢M: Th·ªânh tho·∫£ng th√™m c√°c t·ª´ c·∫£m th√°n nh·∫π nh√†ng ·ªü ƒë·∫ßu c√¢u nh∆∞: 'Ch√†o b·∫°n!', 'R·∫•t th√∫ v·ªã l√†...', 'C√≥ th·ªÉ b·∫°n ch∆∞a bi·∫øt...', 'Th·∫≠t t·ª± h√†o khi...' ƒë·ªÉ tƒÉng t√≠nh t∆∞∆°ng t√°c.\n"
    "\n--- QUY T·∫ÆC N·ªòI DUNG ---\n"
    "1. NG√îN NG·ªÆ: Ph·∫£n h·ªìi b·∫±ng ng√¥n ng·ªØ ng∆∞·ªùi d√πng ƒë√£ h·ªèi (Ti·∫øng Anh ho·∫∑c Ti·∫øng Vi·ªát).\n"
    "2. GI·ªöI H·∫†N D·ªÆ LI·ªÜU: Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin trong CONTEXT. Kh√¥ng ƒë∆∞·ª£c b·ªãa ƒë·∫∑t.\n"
    "3. X·ª¨ L√ù KHI THI·∫æU TIN: N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu, h√£y n√≥i: 'Ti·∫øc qu√°, hi·ªán t·∫°i m√¨nh ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ ph·∫ßn n√†y. B·∫°n c√≥ mu·ªën t√¨m hi·ªÉu v·ªÅ [g·ª£i √Ω m·ªôt ch·ªß ƒë·ªÅ trong context] kh√¥ng?'.\n"
    "4. T·ªêI ∆ØU CHO GI·ªåNG ƒê·ªåC (TTS):\n"
    "   - Tr√¨nh b√†y d·∫°ng ƒëo·∫°n vƒÉn m·∫°ch l·∫°c, KH√îNG d√πng g·∫°ch ƒë·∫ßu d√≤ng hay danh s√°ch s·ªë.\n"
    "   - ∆Øu ti√™n c√¢u ng·∫Øn, ng·∫Øt ngh·ªâ ƒë√∫ng ch·ªó b·∫±ng d·∫•u ch·∫•m, d·∫•u ph·∫©y.\n"
    "   - Tr√°nh c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát, icon ho·∫∑c b·∫£ng bi·ªÉu trong l·ªùi n√≥i."
)

# ====== AUDIO ENGINE ======
def tts_play(text: str):
    text = (text or "").strip()
    clean_text = re.sub(r'[^\w\s,.!??√°√†·∫£√£·∫°√¢·∫•·∫ß·∫©·∫´·∫≠ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµ]', '', text).strip()
    
    if not clean_text or len(clean_text) < 2:
        return
        
    try:
        # T·ª± ƒë·ªông nh·∫≠n di·ªán ng√¥n ng·ªØ c·ªßa c√¢u tr·∫£ l·ªùi
        lang_code = 'vi'
        try:
            detected_lang = detect(text)
            if detected_lang == 'en':
                lang_code = 'en'
        except:
            pass # N·∫øu l·ªói th√¨ m·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát
            
        tts = gTTS(text=clean_text, lang=lang_code, slow=False)

        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        b64 = base64.b64encode(fp.read()).decode()
        audio_uri = f"data:audio/mp3;base64,{b64}"
        
        js_code = f"""
            <script>
                (function() {{
                    const audioUri = "{audio_uri}";
                    
                    // 1. ƒê∆∞a c√¢u m·ªõi v√†o h√†ng ƒë·ª£i chung
                    let queue = JSON.parse(localStorage.getItem('audio_queue') || '[]');
                    queue.push(audioUri);
                    localStorage.setItem('audio_queue', JSON.stringify(queue));

                    // 2. H√†m qu·∫£n l√Ω vi·ªác ph√°t nh·∫°c
                    function startManager() {{
                        if (window.audioManagerInterval) clearInterval(window.audioManagerInterval);
                        
                        window.audioManagerInterval = setInterval(() => {{
                            // N·∫øu ƒëang ph√°t th√¨ th√¥i, ƒë·ª£i v√≤ng l·∫∑p k·∫ø ti·∫øp ki·ªÉm tra l·∫°i
                            if (localStorage.getItem('is_audio_playing') === 'true') return;

                            let currentQueue = JSON.parse(localStorage.getItem('audio_queue') || '[]');
                            if (currentQueue.length === 0) {{
                                clearInterval(window.audioManagerInterval);
                                return;
                            }}

                            // L·∫•y c√¢u ti·∫øp theo ra ph√°t
                            localStorage.setItem('is_audio_playing', 'true');
                            let nextUri = currentQueue.shift();
                            localStorage.setItem('audio_queue', JSON.stringify(currentQueue));

                            let audio = new Audio(nextUri);
                            audio.playbackRate = 1.4;
                            
                            audio.onended = function() {{
                                localStorage.setItem('is_audio_playing', 'false');
                            }};
                            
                            audio.play().catch(e => {{
                                localStorage.setItem('is_audio_playing', 'false');
                            }});
                        }}, 200); // Ki·ªÉm tra h√†ng ƒë·ª£i m·ªói 0.2 gi√¢y
                    }}

                    startManager();
                }})();
            </script>
        """
        st.components.v1.html(js_code, height=0)
    except Exception:
        pass

# ====== HELPERS ======
def init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]

def chunk_markdown(md_text: str) -> List[Dict]:
    headers_to_split_on = [("#", "h1"), ("##", "h2"), ("###", "h3")]
    splitter1 = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
    sections = splitter1.split_text(md_text)
    splitter2 = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=180)
    docs = splitter2.split_documents(sections)
    return [{"content": d.page_content.strip(), "metadata": d.metadata} for d in docs if d.page_content.strip()]

@st.cache_resource(show_spinner="üîÑ NPC ƒëang kh·ªüi ƒë·ªông...")
def setup_system():
    api_key = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    embedding = Embeddings(model_name="text-embedding-3-small")
    vector_db = VectorDatabase(db_name=DB_NAME)
    reflector = Reflection(llm_client=client)
    reranker = None #Reranker(model_name="BAAI/bge-reranker-v2-m3")

    routes = [
        Route(name="roi_nuoc", samples=samples.roiNuocSample, filter_dict={"culture_type": "mua_roi_nuoc"}),
        Route(name="hoang_thanh", samples=samples.hoangThanhSample, filter_dict={"culture_type": "hoang_thanh"}),
        Route(name="chitchat", samples=samples.chitchatSample, filter_dict={}),
    ]
    router = SemanticRouter(embedding=embedding, routes=routes, threshold=0.5)

    # Ingest data
    for culture_type, file_path in CULTURE_FILES:
        if vector_db.count_documents(COLLECTION_NAME, {"culture_type": culture_type}) == 0:
            if os.path.exists(file_path):
                md = open(file_path, "r", encoding="utf-8").read()
                chunks = chunk_markdown(md)
                vectors = embedding.encode([c["content"] for c in chunks])
                docs = [{"content": c["content"], "embedding": vectors[i], "culture_type": culture_type, "metadata": c["metadata"]} for i, c in enumerate(chunks)]
                vector_db.insert_many(COLLECTION_NAME, docs)
    return client, embedding, vector_db, router, reflector, reranker

# ====== LOGIC X·ª¨ L√ù CH√çNH ======
def handle_query(user_input: str, client: OpenAI, embedding: Embeddings, vector_db: VectorDatabase,
                 router: SemanticRouter, reflector: Reflection, reranker: Reranker):

    if len(user_input.strip().split()) <= 2:
        ans = "Ch√†o b·∫°n! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n v·ªÅ M√∫a r·ªëi n∆∞·ªõc ho·∫∑c Ho√†ng th√†nh ThƒÉng Long?"
        st.markdown(ans)
        tts_play(ans)
        st.session_state.messages.append({"role": "assistant", "content": ans})
        return

    # 1) SMART REFLECTION (T·ªëi ∆∞u t·ªëc ƒë·ªô)
    ambiguous_keywords = ["n√≥", "ƒë√≥", "ƒë·∫•y", "kia", "·∫•y", "h·ªç", "√¥ng ·∫•y", "b√† ·∫•y", "·ªü ƒë√≥", "ch·ªó ƒë√≥"]
    is_ambiguous = any(word in user_input.lower() for word in ambiguous_keywords)
    word_count = len(user_input.strip().split())

    # N·∫øu c√¢u h·ªèi d√†i (>10 t·ª´) v√† kh√¥ng ch·ª©a t·ª´ m∆° h·ªì, ho·∫∑c l√† c√¢u h·ªèi ƒë·∫ßu ti√™n -> B·ªè qua Rewrite
    if word_count > 10 and not is_ambiguous:
        rewritten = user_input
        st.caption("‚ö° **Fast-Track**: B·ªè qua b∆∞·ªõc l√†m r√µ (C√¢u h·ªèi ƒë·ªß √Ω)")
    elif len(st.session_state.messages) <= 1:
        rewritten = user_input
        st.caption("‚ö° **First Query**: ƒêi th·∫≥ng v√†o t√¨m ki·∫øm")
    else:
        # Ch·ªâ g·ªçi GPT rewrite khi th·ª±c s·ª± c·∫ßn ng·ªØ c·∫£nh c√¢u tr∆∞·ªõc
        rewritten = reflector.rewrite(st.session_state.messages, user_input)
        st.caption(f"üîç **Reflected**: {rewritten}")
    
    # 2) ROUTER
    score, route_name, filter_dict = router.guide(rewritten)
    st.caption(f"üß≠ Route: {route_name} ({score:.2f})")

    if route_name in ("uncertain", "chitchat"):
        ans = "T√¥i l√† NPC chuy√™n tr√°ch di s·∫£n. B·∫°n vui l√≤ng h·ªèi c·ª• th·ªÉ v·ªÅ M√∫a r·ªëi n∆∞·ªõc ho·∫∑c Ho√†ng th√†nh nh√©!"
        st.markdown(ans)
        tts_play(ans)
        st.session_state.messages.append({"role": "assistant", "content": ans})
        return

    # Retrieval & Rerank
    # 1. Retrieval (L·∫•y r·ªông ra m·ªôt ch√∫t) -> d√πng hybrid(x·ª≠ l√≠ th√¥: t√¨m sl t·ª´ gi·ªëng nhau + gpt) ƒë·ªÉ ki·ªÉm tra rerank
    # B∆Ø·ªöC 1: RETRIEVAL
    q_vec = embedding.encode([rewritten])[0]
    results = vector_db.query(COLLECTION_NAME, q_vec, limit=15, filter_dict=filter_dict)

    if not results:
        st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p.")
        return

    # B∆Ø·ªöC 2: L·ªåC TH√î (HEURISTIC)
    import re
    def simple_keyword_score(text, query):
        # Ch·ªâ l·∫•y c√°c t·ª´ c√≥ nghƒ©a (ƒë·ªô d√†i > 2) ƒë·ªÉ tr√°nh stopwords
        query_words = set(re.findall(r'\w{3,}', query.lower()))
        text_lower = text.lower()
        # Th∆∞·ªüng ƒëi·ªÉm cho t·ª´ kh√≥a: +1 ƒëi·ªÉm m·ªói t·ª´ xu·∫•t hi·ªán
        score = sum(1.5 if w in text_lower else 0 for w in query_words)
        # Th∆∞·ªüng th√™m n·∫øu ch·ª©a t·ª´ vi·∫øt hoa (t√™n ri√™ng) t·ª´ c√¢u h·ªèi g·ªëc
        proper_nouns = re.findall(r'\b[A-Z][a-z]+\b', rewritten)
        for pn in proper_nouns:
            if pn.lower() in text_lower: score += 2.0
        return score

    for r in results:
        k_score = simple_keyword_score(r['content'], rewritten)
        # Vector score th∆∞·ªùng nh·ªè (0.5-0.8), n√™n k_score c·∫ßn tr·ªçng s·ªë ph√π h·ª£p
        r['hybrid_score'] = r.get('score', 0) + (k_score * 0.1)

    results.sort(key=lambda x: x['hybrid_score'], reverse=True)
    top_candidates = results[:5]
    passages = [r["content"] for r in top_candidates]

    # B∆Ø·ªöC 3: L·ªåC TINH (LLM RERANK)
    # Th√™m ph√¢n c√°ch r√µ r√†ng ƒë·ªÉ GPT kh√¥ng b·ªã "lo·∫°n" m·∫Øt
    rerank_input = "\n\n".join([f"--- ƒêO·∫†N [{i}] ---\n{p}" for i, p in enumerate(passages)])
    
    rerank_prompt = f"""
    D·ª±a v√†o c√°c ƒëo·∫°n vƒÉn sau, h√£y ch·ªçn ra ID c·ªßa nh·ªØng ƒëo·∫°n ch·ª©a th√¥ng tin tr·ª±c ti·∫øp ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.
    C√¢u h·ªèi: {rewritten}
    
    {rerank_input}
    
    Ch·ªâ tr·∫£ v·ªÅ s·ªë th·ª© t·ª± [index] trong ngo·∫∑c vu√¥ng, v√≠ d·ª•: [0, 2]. N·∫øu kh√¥ng c√≥ th√¥ng tin, tr·∫£ v·ªÅ [None].
    """

    context = ""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "B·∫°n l√† b·ªô l·ªçc d·ªØ li·ªáu ch√≠nh x√°c. Ch·ªâ tr·∫£ v·ªÅ ID."},
                      {"role": "user", "content": rerank_prompt}],
            temperature=0,
            timeout=5
        )
        
        raw_res = response.choices[0].message.content.strip()
        # Regex n√†y s·∫Ω l·∫•y m·ªçi con s·ªë n·∫±m trong chu·ªói
        selected_indices = [int(i) for i in re.findall(r'\d+', raw_res)]
        
        final_passages = [passages[i] for i in selected_indices if i < len(passages)]
        context = "\n\n".join(final_passages) if final_passages else passages[0]
        
    except Exception as e:
        # B·∫£o v·ªá: n·∫øu passages tr·ªëng th√¨ g√°n chu·ªói r·ªóng, n·∫øu c√≥ th√¨ l·∫•y c√°i ƒë·∫ßu ti√™n
        context = passages[0] if passages else ""
#----- c2: Retrieval & Rerank(s·ª≠ d·ª•ng model c√≥ s·∫µn)

    # q_vec = embedding.encode([rewritten])[0]
    # results = vector_db.query(COLLECTION_NAME, q_vec, limit=TOP_K_RETRIEVAL, filter_dict=filter_dict)
    
    # if not results:
    #     ans = "Xin l·ªói, t√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ ph·∫ßn n√†y."
    #     st.markdown(ans)
    #     tts_play(ans)
    #     return

    # passages = [r["content"] for r in results if r.get("content")]
    # _, ranked_passages = reranker.rerank(rewritten, passages, threshold=0.4)
    # context = "\n\n".join(ranked_passages[:TOP_K_FINAL] if ranked_passages else passages[:3])

#-------c3: b·ªè rerank -> r·ªßi ro ch√≠nh x√°c

    ## 3) Retrieval (Ch·ªâ gi·ªØ l·∫°i ph·∫ßn n√†y, b·ªè Rerank)
    # q_vec = embedding.encode([rewritten])[0]
    # results = vector_db.query(
    #     collection_name=COLLECTION_NAME, 
    #     query_vector=q_vec, 
    #     limit=5, # L·∫•y th·∫≥ng 5 k·∫øt qu·∫£ t·ªët nh·∫•t thay v√¨ 15
    #     filter_dict=filter_dict
    # )
    
    # if not results:
    #     ans = "Xin l·ªói, t√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ ph·∫ßn n√†y."
    #     st.markdown(ans)
    #     tts_play(ans)
    #     st.session_state.messages.append({"role": "assistant", "content": ans})
    #     return

    # # L·∫•y n·ªôi dung tr·ª±c ti·∫øp t·ª´ k·∫øt qu·∫£ t√¨m ki·∫øm (Skip b∆∞·ªõc Rerank)
    # context_passages = [r["content"] for r in results if r.get("content")]
    # context = "\n\n".join(context_passages).strip()

    # Generator with Streaming + Real-time TTS
    ph = st.empty()
    full_answer = ""
    sentence_buffer = ""

    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": f"CONTEXT:\n{context}\n\nQ: {rewritten}"}],
        stream=True
    )

    for chunk in stream:
        delta = chunk.choices[0].delta.content
        if delta:
            full_answer += delta
            sentence_buffer += delta
            ph.markdown(full_answer + "‚ñå")
            
            # N·∫øu g·∫∑p d·∫•u ng·∫Øt c√¢u, ph√°t √¢m thanh ngay
            if any(p in delta for p in [".", "?", "!", "\n", ":"]):
                if len(sentence_buffer.strip()) > 5:
                    tts_play(sentence_buffer)
                    sentence_buffer = ""

    if sentence_buffer.strip():
        tts_play(sentence_buffer)

    ph.markdown(full_answer)
    st.session_state.messages.append({"role": "assistant", "content": full_answer})

# ====== UI UI UI ======
st.set_page_config(page_title="NPC Di s·∫£n Vi·ªát Nam", layout="wide")
st.title("üèØ NPC Di s·∫£n Vi·ªát Nam (Real-time Voice)")

init_session()
client, embedding, vector_db, router, reflector, reranker = setup_system()

for msg in st.session_state.messages[1:]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("H·ªèi v·ªÅ di s·∫£n...")
if user_input:

    st.components.v1.html("""
        <script>
            localStorage.setItem('audio_queue', '[]'); 
            localStorage.setItem('is_audio_playing', 'false');
            // D·ª´ng ngay l·∫≠p t·ª©c √¢m thanh ƒëang ph√°t (n·∫øu c√≥)
            if (window.currentAudio) { window.currentAudio.pause(); } 
        </script>
    """, height=0)

    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    with st.chat_message("assistant"):
        handle_query(user_input, client, embedding, vector_db, router, reflector, reranker)