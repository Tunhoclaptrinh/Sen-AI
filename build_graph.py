"""
build_graph.py â€” Script cháº¡y 1 láº§n Ä‘á»ƒ build Knowledge Graph
tá»« toÃ n bá»™ chunks Ä‘Ã£ cÃ³ trong MongoDB.

CÃ¡ch dÃ¹ng:
    python build_graph.py
    python build_graph.py --site hoang_thanh   # Chá»‰ build cho 1 di tÃ­ch
    python build_graph.py --dry-run             # Chá»‰ xem káº¿t quáº£, khÃ´ng lÆ°u
"""

import os
import json
import asyncio
import logging
import argparse
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)

# â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BATCH_SIZE = 5          # Sá»‘ chunks xá»­ lÃ½ má»—i láº§n gá»i GPT
MAX_TRIPLES_PER_CHUNK = 10
COLLECTIONS_TO_SCAN = ["heritage", "culture", "history"]


# â”€â”€â”€ GPT Extraction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

EXTRACTION_SYSTEM_PROMPT = """Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch vÄƒn báº£n lá»‹ch sá»­ vÃ  vÄƒn hÃ³a Viá»‡t Nam.
Nhiá»‡m vá»¥: TrÃ­ch xuáº¥t cÃ¡c quan há»‡ cÃ³ Ã½ nghÄ©a tá»« Ä‘oáº¡n vÄƒn báº£n Ä‘Æ°á»£c cung cáº¥p.

QUY Táº®C:
1. Chá»‰ trÃ­ch xuáº¥t quan há»‡ RÃ• RÃ€NG cÃ³ trong vÄƒn báº£n, KHÃ”NG suy diá»…n thÃªm
2. Subject vÃ  Object pháº£i lÃ  danh tá»«/tÃªn riÃªng cá»¥ thá»ƒ (Ä‘á»‹a danh, nhÃ¢n váº­t, triá»u Ä‘áº¡i, sá»± kiá»‡n)
3. Relation pháº£i lÃ  Ä‘á»™ng tá»«/quan há»‡ ngáº¯n gá»n báº±ng TIáº¾NG VIá»†T IN HOA vá»›i dáº¥u gáº¡ch dÆ°á»›i

CÃC LOáº I RELATION Há»¢P Lá»†:
- XÃ‚Y_Bá»I, ÄÆ¯á»¢C_XÃ‚Y_Dá»°NG_NÄ‚M, THUá»˜C_TRIá»€U_Äáº I
- CÃ“_NHÃ‚N_Váº¬T, LÃ€_VUA, LÃ€_TÆ¯á»šNG, LÃ€_NHÃ€_THÆ 
- Náº°M_Táº I, THUá»˜C_DI_TÃCH, CÃ“_CÃ”NG_TRÃŒNH
- ÄÆ¯á»¢C_UNESCO_CÃ”NG_NHáº¬N_NÄ‚M, LÃ€_DI_Sáº¢N
- CHIáº¾N_THáº®NG, THáº¤T_Báº I_TRÆ¯á»šC, Äá»’NG_MINH_Cá»¦A
- LIÃŠN_QUAN_Äáº¾N, Káº¾_THá»ªA_Tá»ª, THAY_THáº¾_Bá»I
- RA_Äá»œI_NÄ‚M, Káº¾T_THÃšC_NÄ‚M, DIá»„N_RA_NÄ‚M

VÃ Dá»¤ OUTPUT (JSON array):
[
  {"s": "HoÃ ng ThÃ nh ThÄƒng Long", "r": "XÃ‚Y_Bá»I", "o": "LÃ½ ThÃ¡i Tá»•", "confidence": 0.95},
  {"s": "LÃ½ ThÃ¡i Tá»•", "r": "THUá»˜C_TRIá»€U_Äáº I", "o": "NhÃ  LÃ½", "confidence": 0.98},
  {"s": "NhÃ  LÃ½", "r": "RA_Äá»œI_NÄ‚M", "o": "1009", "confidence": 0.9}
]

Tráº£ vá» JSON array THUáº¦N TÃšY, khÃ´ng markdown, khÃ´ng giáº£i thÃ­ch."""


async def extract_triples_from_chunk(
    chunk_text: str,
    openai_client: AsyncOpenAI,
    site_key: str = ""
) -> list:
    """
    DÃ¹ng GPT extract quan há»‡ tá»« 1 Ä‘oáº¡n vÄƒn báº£n.
    Returns: [{"s": ..., "r": ..., "o": ..., "confidence": ...}]
    """
    if not chunk_text or len(chunk_text.strip()) < 30:
        return []

    user_prompt = f"""Di tÃ­ch/Chá»§ Ä‘á»: {site_key}

VÄƒn báº£n:
{chunk_text[:2000]}

TrÃ­ch xuáº¥t tá»‘i Ä‘a {MAX_TRIPLES_PER_CHUNK} quan há»‡ quan trá»ng nháº¥t."""

    try:
        res = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": EXTRACTION_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0,
            max_tokens=800
        )

        raw = res.choices[0].message.content.strip()

        # Clean markdown code blocks náº¿u cÃ³
        if raw.startswith("```"):
            raw = raw.split("```")[1]
            if raw.startswith("json"):
                raw = raw[4:]

        triples = json.loads(raw)
        if isinstance(triples, list):
            return triples
        return []

    except json.JSONDecodeError as e:
        logger.warning(f"   âš ï¸ JSON parse error: {e} | Raw: {raw[:100]}")
        return []
    except Exception as e:
        logger.error(f"   âŒ GPT extraction error: {e}")
        return []


async def extract_triples_batch(
    chunks: list,
    openai_client: AsyncOpenAI,
    site_key: str
) -> list:
    """Xá»­ lÃ½ nhiá»u chunks song song."""
    tasks = [
        extract_triples_from_chunk(c["content"], openai_client, site_key)
        for c in chunks
        if c.get("content")
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    all_triples = []
    for r in results:
        if isinstance(r, list):
            all_triples.extend(r)
    return all_triples


# â”€â”€â”€ Main Build Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def build_graph(target_site: str = None, dry_run: bool = False):
    """
    Äá»c toÃ n bá»™ chunks tá»« MongoDB â†’ extract triples â†’ lÆ°u vÃ o knowledge_graph.
    """
    from app.core.vector_db import VectorDatabase
    from app.core.graph_store import GraphStore
    from app.core.config_loader import get_heritage_config

    logger.info("=" * 60)
    logger.info("ğŸ•¸ï¸  BUILD KNOWLEDGE GRAPH â€” Hybrid RAG")
    logger.info("=" * 60)

    # Init
    v_db = VectorDatabase(db_name="vector_db")
    graph = GraphStore(v_db.db)
    openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    config = get_heritage_config()

    # Filter sites
    if target_site:
        sites = {target_site: config.get(target_site, {})}
        logger.info(f"ğŸ¯ Target site: {target_site}")
    else:
        sites = config
        logger.info(f"ğŸŒ Processing all {len(sites)} sites")

    total_triples = 0

    for site_key, site_data in sites.items():
        collection = site_data.get("collection", "culture")
        site_name = site_data.get("name", site_key)

        logger.info(f"\n{'â”€'*50}")
        logger.info(f"ğŸ“ Site: {site_name} ({site_key}) â†’ Collection: {collection}")

        # XÃ¡c Ä‘á»‹nh filter field
        filter_map = {
            "heritage": "heritage_type",
            "culture": "culture_type",
            "history": "history_type"
        }
        type_field = filter_map.get(collection, "culture_type")

        # Äá»c chunks tá»« MongoDB
        if v_db.db is None:
            logger.error("âŒ MongoDB khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c!")
            continue

        chunks = list(
            v_db.db[collection].find(
                {type_field: site_key},
                {"_id": 0, "content": 1, "metadata": 1}
            )
        )

        if not chunks:
            logger.warning(f"   âš ï¸ KhÃ´ng cÃ³ chunks nÃ o cho {site_key} trong '{collection}'")
            continue

        logger.info(f"   ğŸ“„ TÃ¬m tháº¥y {len(chunks)} chunks â†’ Extract triples...")

        # XÃ³a triples cÅ© cá»§a site nÃ y (Ä‘á»ƒ rebuild)
        if not dry_run:
            old_count = graph.count(site_key)
            if old_count > 0:
                v_db.db["knowledge_graph"].delete_many({"site_key": site_key})
                logger.info(f"   ğŸ—‘ï¸  ÄÃ£ xÃ³a {old_count} triples cÅ©")

        # Extract theo batch
        site_triples = []
        for i in range(0, len(chunks), BATCH_SIZE):
            batch = chunks[i:i + BATCH_SIZE]
            batch_num = i // BATCH_SIZE + 1
            total_batches = (len(chunks) + BATCH_SIZE - 1) // BATCH_SIZE

            logger.info(f"   ğŸ¤– Batch {batch_num}/{total_batches} ({len(batch)} chunks)...")
            triples = await extract_triples_batch(batch, openai_client, site_name)
            site_triples.extend(triples)

            # Rate limit
            await asyncio.sleep(0.5)

        logger.info(f"   âœ… Extracted {len(site_triples)} triples")

        if dry_run:
            logger.info(f"   [DRY RUN] Sample triples:")
            for t in site_triples[:5]:
                logger.info(f"      {t.get('s')} [{t.get('r')}] {t.get('o')}")
        else:
            # LÆ°u vÃ o MongoDB
            source_name = f"build_graph:{site_key}"
            saved = graph.insert_triples(site_triples, site_key, source_name)
            total_triples += saved
            logger.info(f"   ğŸ’¾ Saved {saved} triples to 'knowledge_graph' collection")

    logger.info(f"\n{'='*60}")
    if dry_run:
        logger.info(f"âœ¨ [DRY RUN] Done! (No data written)")
    else:
        logger.info(f"âœ¨ Done! Total triples saved: {total_triples}")
    logger.info(f"{'='*60}\n")


# â”€â”€â”€ Entry Point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Build Knowledge Graph tá»« MongoDB chunks"
    )
    parser.add_argument(
        "--site",
        type=str,
        default=None,
        help="Chá»‰ build cho 1 site cá»¥ thá»ƒ (vd: hoang_thanh)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview káº¿t quáº£, khÃ´ng lÆ°u vÃ o DB"
    )
    args = parser.parse_args()

    asyncio.run(build_graph(target_site=args.site, dry_run=args.dry_run))
