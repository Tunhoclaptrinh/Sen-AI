import base64
import re
from fastapi import FastAPI, File, UploadFile, WebSocket, WebSocketDisconnect
from pydantic import BaseModel
from typing import Optional, List
from edge_tts import Communicate
import redis.asyncio as redis
from dotenv import load_dotenv
from openai import AsyncOpenAI
from sentence_transformers import SentenceTransformer
from vector_db import VectorDatabase
from knowledge_base import KnowledgeBase
from heritage_tool import HeritageTools
import logging
import os
import asyncio
from agentic_rag_workflow import agentic_workflow
import io
from uuid import uuid4
import edge_tts
import tempfile

# Táº£i .env Ä‘á»ƒ láº¥y cÃ¡c biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
ENABLE_FILE_LOGGING = os.getenv("ENABLE_FILE_LOGGING", "true").lower() == "true"

# Khá»Ÿi táº¡o á»©ng dá»¥ng FastAPI
app = FastAPI()

# Cáº¥u hÃ¬nh CORS Ä‘á»ƒ cho phÃ©p Admin Dashboard (hoáº·c frontend khÃ¡c) gá»i API
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Cho phÃ©p táº¥t cáº£ cÃ¡c nguá»“n (trong mÃ´i trÆ°á»ng dev)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



# Khá»Ÿi táº¡o logger
logger = logging.getLogger("uvicorn")

async def generate_tts(text: str) -> str:
    """
    Generate Text-to-Speech: Edge TTS (Primary) -> Google TTS (Fallback).
    Returns: Base64 encoded audio string.
    """
    # 1. Remove Markdown links: [Text](URL) -> Text
    # This ensures TTS reads the description but skips the http link
    clean_text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1', text)

    # 2. Remove standalone URLs (http/https)
    clean_text = re.sub(r'http[s]?://\S+', '', clean_text)
    
    # 3. Remove Markdown chars (*, _, `, ~)
    clean_text = re.sub(r'[*_`~]', '', clean_text)

    # 4. Remove ALL Emojis (Unicode ranges for symbols, pictographs, etc.)
    # Range includes: 1F600-1F64F (Emoticons), 1F300-1F5FF (Symbols), 1F680-1F6FF (Transport), etc.
    clean_text = re.sub(r'[^\w\s,.;:?!Ã¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ä‘Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µ]', '', clean_text)
    
    # 5. Clean up extra spaces
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    temp_dir = tempfile.gettempdir()
    output_file = os.path.join(temp_dir, f"temp_tts_{uuid4()}.mp3")
    
    # 1. Thá»­ Edge TTS (Giá»ng hay)
    VOICE_CANDIDATES = ["vi-VN-HoaiMyNeural", "vi-VN-NamMinhNeural"]
    for voice in VOICE_CANDIDATES:
        try:
            # TÄƒng tá»‘c Ä‘á»™ Ä‘á»c lÃªn Ä‘Ã¡ng ká»ƒ theo yÃªu cáº§u
            communicate = edge_tts.Communicate(clean_text, voice, rate="+30%")
            await communicate.save(output_file)
            
            if os.path.exists(output_file) and os.path.getsize(output_file) > 100:
                with open(output_file, "rb") as f: audio_data = f.read()
                os.remove(output_file)
                return base64.b64encode(audio_data).decode()
        except Exception as e:
            logger.warning(f"âš ï¸ Edge TTS ({voice}) failed: {e}")
            if os.path.exists(output_file): os.remove(output_file)
            continue

    # 2. Fallback: Google TTS (Giá»ng á»•n Ä‘á»‹nh)
    try:
        try:
            from gtts import gTTS
        except ImportError:
            logger.error("âŒ ThÆ° viá»‡n 'gTTS' chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t! Äang cá»‘ gáº¯ng import nhÆ°ng tháº¥t báº¡i.")
            raise

        logger.info("ðŸ”„ Switching to Google TTS fallback...")
        tts = gTTS(text=clean_text, lang='vi')
        tts.save(output_file)
        
        with open(output_file, "rb") as f: audio_data = f.read()
        os.remove(output_file)
        return base64.b64encode(audio_data).decode()
    except Exception as e:
        logger.error(f"âŒ Google TTS also failed: {e}")
        return ""

# Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n cáº§n thiáº¿t cho á»©ng dá»¥ng
@app.on_event("startup")
async def startup():
    # Khá»Ÿi táº¡o Redis káº¿t ná»‘i
    app.state.redis = redis.from_url(os.getenv("REDIS_URL"), decode_responses=True)
    
    # Khá»Ÿi táº¡o OpenAI API
    app.state.openai = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # Khá»Ÿi táº¡o Vector Database vÃ  Sentence Transformer cho KnowledgeBase
    v_db = VectorDatabase(db_name="vector_db")
    embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    # Khá»Ÿi táº¡o KnowledgeBase cho viá»‡c lÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u
    app.state.brain = KnowledgeBase(v_db, embedder)
    
    # Khá»Ÿi táº¡o Verifier module
    from verifier import Verifier
    app.state.verifier = Verifier(app.state.openai)
    
    # Khá»Ÿi táº¡o HeritageTools Ä‘á»ƒ láº¥y thÃ´ng tin thá»i gian thá»±c
    app.state.tools = HeritageTools()
    
    # ThÃªm hÃ m generate_tts vÃ o app.state Ä‘á»ƒ cÃ³ thá»ƒ truy cáº­p tá»« workflow
    app.state.generate_tts = generate_tts

# Äá»‹nh nghÄ©a dá»¯ liá»‡u Ä‘áº§u vÃ o (cÃ¢u há»i vÃ  lá»‹ch sá»­)
class ChatRequest(BaseModel):
    user_input: str
    history: List[dict] = []
    session_id: Optional[str] = None
    use_verifier: bool = False

@app.on_event("shutdown")
async def shutdown():
    # ÄÃ³ng káº¿t ná»‘i Redis khi á»©ng dá»¥ng dá»«ng
    if hasattr(app.state, 'redis'):
        await app.state.redis.close()
    else:
        logger.warning("Redis khÃ´ng Ä‘Æ°á»£c khá»Ÿi táº¡o, khÃ´ng thá»ƒ Ä‘Ã³ng káº¿t ná»‘i.")

@app.get("/chat")
async def chat_get_info():
    """
    Endpoint GET Ä‘á»ƒ hÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng náº¿u há» truy cáº­p nháº§m báº±ng trÃ¬nh duyá»‡t.
    """
    return {
        "message": "ÄÃ¢y lÃ  API Chat (POST). Báº¡n khÃ´ng thá»ƒ truy cáº­p trá»±c tiáº¿p báº±ng trÃ¬nh duyá»‡t (GET).",
        "instruction": "Vui lÃ²ng sá»­ dá»¥ng method POST vá»›i body JSON: {'user_input': '...'}",
        "docs": "Truy cáº­p /docs Ä‘á»ƒ test API."
    }

@app.post("/chat")
async def chat_api(request: ChatRequest):
    """
    API chÃ­nh nháº­n cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng.
    Flow: LLM (detect intent) â†’ [CHITCHAT: return ngay] [REALTIME/HERITAGE: cache check â†’ Process â†’ Cache save]
    """
    try:
        import json
        
        # ðŸ”´ BÆ¯á»šC 1: Gá»i LLM trÆ°á»›c Ä‘á»ƒ phÃ¢n loáº¡i intent (chitchat, realtime, rag)
        logger.info(f"\n{'='*80}")
        logger.info(f"ðŸš€ INPUT: {request.user_input}")
        logger.info(f"{'='*80}")
        
        # Gá»i workflow Ä‘á»ƒ LLM phÃ¢n loáº¡i
        result = await agentic_workflow(request.user_input, request.history, app.state)
        intent = result.get("intent", "chitchat")
        
        logger.info(f"ðŸ“‹ Intent detected: {intent}")
        
        # âœ¨ CHITCHAT: Response ngay (tÃ­nh táº¿, khÃ´ng cache)
        if intent == "chitchat":
            logger.info(f"ðŸ’¬ CHITCHAT mode: Response ngay, khÃ´ng dÃ¹ng cache")
            result["from_cache"] = False
            return result
        
        # ðŸ”´ BÆ¯á»šC 2: Normalize input Ä‘á»ƒ táº¡o cache key (cho realtime/heritage)
        normalized_input = " ".join(request.user_input.lower().split())
        cache_key = f"sen:cache:{normalized_input}"
        
        # ðŸ”´ BÆ¯á»šC 3: Kiá»ƒm tra Redis (chá»‰ cache realtime/heritage)
        logger.info(f"ðŸ” Kiá»ƒm tra cache Redis: {cache_key}")
        cached_result = await app.state.redis.get(cache_key)
        
        if cached_result:
            logger.info(f"âœ… [Step 10] FINISHED (Cache Hit). Data Source: ðŸ’¾ CACHE (Redis)")
            final_res = json.loads(cached_result)
            final_res["from_cache"] = True
            return final_res
        
        logger.info(f"âŒ MISS CACHE. Sá»­ dá»¥ng káº¿t quáº£ vá»«a tÃ­nh tá»« LLM")
        
        # Káº¿t quáº£ Ä‘Ã£ cÃ³ tá»« BÆ¯á»šC 1, khÃ´ng cáº§n gá»i láº¡i workflow
        result["from_cache"] = False
        
        # ðŸ”´ BÆ¯á»šC 4: LÆ°u káº¿t quáº£ vÃ o cache (realtime/rag: 30 phÃºt Ä‘á»ƒ cÃ³ data má»›i)
        cache_ttl = 1800  # 30 minutes cho realtime/heritage
        await app.state.redis.setex(cache_key, cache_ttl, json.dumps(result, ensure_ascii=False))
        logger.info(f"ðŸ’¾ LÆ°u cache vá»›i TTL {cache_ttl}s: {cache_key} (intent: {intent})")
        
        return result
    except Exception as e:
        logger.error(f"âŒ Lá»—i xá»­ lÃ½ cÃ¢u há»i: {str(e)}", exc_info=True)
        import traceback
        return {"error": "CÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh xá»­ lÃ½ yÃªu cáº§u.", "details": str(e), "traceback": traceback.format_exc()}

from fastapi.responses import StreamingResponse

@app.post("/chat/stream")
async def chat_stream_api(request: ChatRequest):
    """
    API Streaming (SSE) cho phÃ©p UI hiá»ƒn thá»‹ tráº¡ng thÃ¡i "Thinking..." theo thá»i gian thá»±c.
    Client sáº½ nháº­n Ä‘Æ°á»£c cÃ¡c event JSON line-by-line.
    Há»— trá»£ Redis Session History náº¿u cÃ³ session_id.
    """
    import json
    
    # [Start] Load History from Redis if session_id provided
    history = request.history
    redis_key = None
    
    if request.session_id:
        redis_key = f"chat_history:{request.session_id}"
        try:
            cached_hist = await app.state.redis.get(redis_key)
            if cached_hist:
                history = json.loads(cached_hist)
                logger.info(f"ðŸ“œ Loaded {len(history)} turns from Redis session: {request.session_id}")
        except Exception as e:
            logger.error(f"âŒ Redis History Load Error: {e}")

    async def event_generator():
        try:
            from agentic_rag_workflow import agentic_workflow_stream
            
            # [Step 1] Initial Log
            yield json.dumps({"status": "start", "message": "Báº¯t Ä‘áº§u xá»­ lÃ½..."}) + "\n"
            
            full_final_res = None

            # [Core Pipeline]
            async for event in agentic_workflow_stream(request.user_input, history, app.state, use_verifier=request.use_verifier):
                yield json.dumps(event) + "\n"
                
                # Check for finish event to save history
                if event.get("status") == "finished":
                    full_final_res = event.get("result")

            # [Step End] Post-processing (Save History)
            if full_final_res:
                try:
                    answer = full_final_res.get("answer", "")
                    site_hint = full_final_res.get("site") 
                    
                    if answer:
                        from datetime import datetime
                        from uuid import uuid4
                        import os
                        
                        # Táº¡o entry
                        new_entry = {
                            "id": str(uuid4()),
                            "user_id": getattr(request, "user_id", "anonymous"),
                            "level_id": getattr(request, "level_id", 1),
                            "character_id": getattr(request, "character_id", 1),
                            "message": request.user_input,
                            "response": answer,
                            "audio_base64": full_final_res.get("audio", ""),
                            "context": {
                                "characterId": getattr(request, "character_id", 1),
                                "rewritten": full_final_res.get("debug_info", {}).get("rewritten", ""),
                                "intent": full_final_res.get("intent", "unknown"),
                                "site": site_hint
                            },
                            "created_at": datetime.utcnow().isoformat() + "Z",
                            "user_input": request.user_input, "generated_answer": answer, "site": site_hint
                        }
                        
                        # 1. Update in-memory history (cho redis)
                        history.append(new_entry)
                        
                        # 2. Save to Redis (if session exists)
                        if redis_key:
                            trimmed_history = history[-20:]
                            await app.state.redis.set(redis_key, json.dumps(trimmed_history, ensure_ascii=False))
                            logger.info(f"ðŸ’¾ Saved to Redis: {redis_key}")
                            
                        # 3. [DEV] Save to local JSON file (Append mode logic)
                        if ENABLE_FILE_LOGGING:
                            log_file = "chat_logs.json"
                            try:
                                current_logs = []
                                if os.path.exists(log_file):
                                    with open(log_file, "r", encoding="utf-8") as f:
                                        try: 
                                            current_logs = json.load(f)
                                            if not isinstance(current_logs, list): current_logs = []
                                        except: current_logs = []
                                        
                                current_logs.append(new_entry)
                                
                                with open(log_file, "w", encoding="utf-8") as f:
                                    json.dump(current_logs, f, ensure_ascii=False, indent=2)
                                logger.info(f"ðŸ“ Appended log to {log_file}")
                            except Exception as file_e:
                                logger.error(f"âŒ File Save Error: {file_e}")

                except Exception as e:
                    logger.error(f"âŒ Post-processing Error: {e}")

        except Exception as e:
            yield json.dumps({"status": "error", "message": str(e)}) + "\n"

    return StreamingResponse(event_generator(), media_type="application/x-ndjson")

class TTSRequest(BaseModel):
    text: str

@app.post("/api/tts")
async def tts_endpoint(req: TTSRequest):
    """
    API chuyá»ƒn vÄƒn báº£n thÃ nh giá»ng nÃ³i (TTS).
    Tráº£ vá» chuá»—i base64 cá»§a file Ã¢m thanh.
    """
    if not req.text:
        return {"audio": ""}
    
    # Sá»­ dá»¥ng hÃ m generate_tts cÃ³ sáºµn
    audio_base64 = await generate_tts(req.text)
    return {"audio": audio_base64}

@app.post("/chat-audio")
async def chat_audio_api(
    audio_file: UploadFile = File(...),
    history: str = ""
):
    """
    API nháº­n audio tá»« ngÆ°á»i dÃ¹ng.
    Flow: Audio â†’ STT (Whisper) â†’ Text â†’ agentic_workflow â†’ TTS â†’ Audio output
    """
    try:
        import json
        
        logger.info(f"\n{'='*80}")
        logger.info(f"ðŸŽ™ï¸ AUDIO INPUT: {audio_file.filename}")
        logger.info(f"{'='*80}")
        
        # ðŸ”´ BÆ¯á»šC 1: Convert audio to text (STT using OpenAI Whisper)
        logger.info(f"ðŸ”„ STT: Chuyá»ƒn audio thÃ nh text...")
        audio_data = await audio_file.read()
        
        # Gá»i OpenAI Whisper API
        transcript = await app.state.openai.audio.transcriptions.create(
            model="whisper-1",
            file=("audio.webm", io.BytesIO(audio_data), "audio/webm")
        )
        
        user_input = transcript.text
        logger.info(f"âœ… STT Result: {user_input}")
        
        # Parse history tá»« JSON string
        try:
            history_list = json.loads(history) if history else []
        except:
            history_list = []
        
        # ðŸ”´ BÆ¯á»šC 2: Gá»i agentic_workflow nhÆ° endpoint /chat
        result = await agentic_workflow(user_input, history_list, app.state)
        intent = result.get("intent", "chitchat")
        
        logger.info(f"ðŸ“‹ Intent detected: {intent}")
        
        # ðŸ”´ BÆ¯á»šC 3: CHITCHAT â†’ return ngay
        if intent == "chitchat":
            logger.info(f"ðŸ’¬ CHITCHAT mode: Response ngay, khÃ´ng dÃ¹ng cache")
            result["from_cache"] = False
            result["transcribed_text"] = user_input  # ThÃªm text Ä‘Ã£ transcribe
            return result
        
        # ðŸ”´ BÆ¯á»šC 4: REALTIME/HERITAGE â†’ check cache
        normalized_input = " ".join(user_input.lower().split())
        cache_key = f"sen:cache:{normalized_input}"
        
        logger.info(f"ðŸ” Kiá»ƒm tra cache Redis: {cache_key}")
        cached_result = await app.state.redis.get(cache_key)
        
        if cached_result:
            logger.info(f"âœ… [Step 10] FINISHED (Cache Hit). Data Source: ðŸ’¾ CACHE (Redis)")
            cached_result_obj = json.loads(cached_result)
            cached_result_obj["from_cache"] = True
            cached_result_obj["cache_key"] = cache_key
            cached_result_obj["transcribed_text"] = user_input
            return cached_result_obj
        
        logger.info(f"âŒ MISS CACHE. Sá»­ dá»¥ng káº¿t quáº£ vá»«a tÃ­nh tá»« LLM")
        
        result["from_cache"] = False
        result["transcribed_text"] = user_input
        
        # ðŸ”´ BÆ¯á»šC 5: LÆ°u káº¿t quáº£ vÃ o cache
        cache_ttl = 1800  # 30 minutes
        await app.state.redis.setex(cache_key, cache_ttl, json.dumps(result, ensure_ascii=False))
        logger.info(f"ðŸ’¾ LÆ°u cache vá»›i TTL {cache_ttl}s: {cache_key} (intent: {intent})")
        
        return result
        
    except Exception as e:
        # Xá»­ lÃ½ lá»—i Audio ngáº¯n hoáº·c lá»—i OpenAI
        error_msg = str(e)
        logger.error(f"âŒ Lá»—i xá»­ lÃ½ audio: {error_msg}", exc_info=True)
        
        friendly_msg = "Dáº¡, Sen Ä‘ang gáº·p chÃºt trá»¥c tráº·c khi nghe. BÃ¡c nÃ³i láº¡i giÃºp Sen nhÃ©!"
        transcribed = "(Lá»—i ká»¹ thuáº­t)"

        if "audio_too_short" in error_msg or "Minimum audio length" in error_msg:
             friendly_msg = "Dáº¡ Sen nghe chÆ°a rÃµ, bÃ¡c nÃ³i láº¡i dÃ i hÆ¡n chÃºt nhÃ©! ðŸŽ¤"
             transcribed = "(Ã‚m thanh quÃ¡ ngáº¯n)"
        
        # Generate TTS for error message to keep UX consistent
        try:
            audio_b64 = await generate_tts(friendly_msg)
        except:
            audio_b64 = ""

        return {
           "intent": "chitchat",
           "answer": friendly_msg,
           "transcribed_text": transcribed,
           "from_cache": False,
           "audio": audio_b64
        }


@app.get("/")
async def health():
    """
    Endpoint kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng.
    """
    return {"status": "Sen NPC Online! âœ¨"}

@app.get("/data-source")
async def data_source_info():
    """
    Endpoint kiá»ƒm tra nguá»“n dá»¯ liá»‡u hiá»‡n táº¡i Ä‘ang sá»­ dá»¥ng.
    Tráº£ vá» thÃ´ng tin vá» dá»¯ liá»‡u cÃ o (scraped) hay default (hardcoded).
    """
    from data_manager import get_data_source_info
    info = get_data_source_info()
    return {
        "data_source": info,
        "message": "ðŸ”„ Dá»¯ liá»‡u Ä‘Æ°á»£c load tá»« file JSON (data/monuments.json). Chá»‰nh sá»­a file nÃ y Ä‘á»ƒ thÃªm/bá»›t di tÃ­ch."
    }



@app.get("/cache/stats")
async def cache_stats():
    """
    Endpoint kiá»ƒm tra thá»‘ng kÃª cache redis.
    Hiá»ƒn thá»‹ danh sÃ¡ch cÃ¡c cÃ¢u há»i Ä‘Ã£ cache vÃ  TTL cÃ²n láº¡i.
    """
    try:
        # Láº¥y táº¥t cáº£ keys trong redis cÃ³ pattern "sen:cache:*"
        keys = await app.state.redis.keys("sen:cache:*")
        
        cache_entries = []
        for key in keys:
            ttl = await app.state.redis.ttl(key)
            data = await app.state.redis.get(key)
            
            # Extract query from cache key
            query = key.replace("sen:cache:", "")
            
            try:
                parsed_data = json.loads(data)
                cache_entries.append({
                    "query": query,
                    "key": key,
                    "ttl_seconds": ttl,
                    "intent": parsed_data.get("intent"),
                    "answer_preview": parsed_data.get("answer", "")[:50],
                    "data_source": parsed_data.get("data_source", {}).get("final_context_source")
                })
            except:
                pass
        
        return {
            "total_cached_queries": len(cache_entries),
            "cache_entries": sorted(cache_entries, key=lambda x: x["ttl_seconds"], reverse=True),
            "message": f"ðŸ“Š CÃ³ {len(cache_entries)} cÃ¢u há»i trong cache. TTL: giÃ¢y"
        }
    except Exception as e:
        logger.error(f"âŒ Error getting cache stats: {e}")
        return {"error": str(e), "cache_entries": []}

@app.post("/cache/clear")
async def clear_cache():
    """
    Endpoint xÃ³a toÃ n bá»™ cache redis (Public for now, should move to admin router).
    """
    try:
        keys = await app.state.redis.keys("sen:cache:*")
        if keys:
            await app.state.redis.delete(*keys)
            logger.info(f"ðŸ—‘ï¸ XÃ³a {len(keys)} entries khá»i cache")
            return {"status": "success", "message": f"âœ… ÄÃ£ xÃ³a sáº¡ch {len(keys)} records trong Cache!", "deleted_count": len(keys)}
        else:
            return {"status": "success", "message": "â„¹ï¸ Cache Ä‘Ã£ trá»‘ng sáºµn, khÃ´ng cáº§n xÃ³a.", "deleted_count": 0}
    except Exception as e:
        logger.error(f"âŒ Error clearing cache: {e}")
        return {"status": "error", "message": str(e)}

@app.delete("/cache/{query}")
async def delete_cache_entry(query: str):
    """
    Endpoint xÃ³a má»™t entry cá»¥ thá»ƒ trong cache.
    """
    try:
        normalized_query = " ".join(query.lower().split())
        cache_key = f"sen:cache:{normalized_query}"
        
        result = await app.state.redis.delete(cache_key)
        
        if result:
            logger.info(f"ðŸ—‘ï¸ XÃ³a cache entry: {cache_key}")
            return {"message": f"âœ… XÃ³a cache entry thÃ nh cÃ´ng: {query}", "deleted": True}
        else:
            return {"message": f"â„¹ï¸ KhÃ´ng tÃ¬m tháº¥y cache entry: {query}", "deleted": False}
    except Exception as e:
        logger.error(f"âŒ Error deleting cache entry: {e}")
@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    try:
        data = await websocket.receive_json()
        
        # Determine Input Type
        # msg_type = data.get("type", "text_input") # default to text if missing
        # user_input = ""
        
        # if msg_type == "audio_input":
        #      audio_b64 = data.get("audio")
        #      if audio_b64:
        #          import io
        #          # Decode Base64
        #          audio_bytes = base64.b64decode(audio_b64)
        #          # Transcribe via Whisper
        #          transcript = await app.state.openai.audio.transcriptions.create(
        #             model="whisper-1",
        #             file=("audio.webm", io.BytesIO(audio_bytes), "audio/webm")
        #          )
        #          user_input = transcript.text
        #          logger.info(f"ðŸŽ™ï¸ WS Audio Transcribed: {user_input}")
                 
        #          # Send transcription back to UI (optional but good for UX)
        #          await websocket.send_json({"type": "text", "content": f"ðŸŽ¤ {user_input}"}) # Or logic to show user prompt
        
        # elif msg_type == "text_input":
        #      user_input = data.get("text")
             
        # # Fallback / Legacy
        # if not user_input:
        #      user_input = data.get("user_input", "")

        session_id = data.get("session_id")
        history = data.get("history", [])

        # [Redis Load]
        redis_key = None
        if session_id:
            redis_key = f"chat_history:{session_id}"
            try:
                cached = await app.state.redis.get(redis_key)
                if cached:
                    import json
                    history = json.loads(cached)
            except Exception as e:
                logger.error(f"WS Redis Load Error: {e}")

        # Processing
        from agentic_rag_workflow import agentic_workflow_stream
        import json
        
        buffer = ""
        full_answer = ""
        full_final_res = None
        
        await websocket.send_json({"type": "status", "message": "Thinking..."})

        async for event in agentic_workflow_stream(user_input, history, app.state):
            # 1. Forward process events
            if event.get("status") in ["processing", "start"]:
                await websocket.send_json({"type": "status", "message": event.get("message")})
            
            # 2. Text Streaming & TTS Buffering
            if event.get("status") == "streaming":
                chunk = event.get("content", "")
                full_answer += chunk
                buffer += chunk
                
                # Send text chunk immediately
                await websocket.send_json({"type": "text", "content": chunk})
                
                # Check sentence end for TTS
                if re.search(r'[.!?\n]+$', buffer.strip()) and len(buffer.strip()) > 10:
                    # Generate Audio for this sentence
                    logging.info(f"ðŸŽ¤ Auto-TTS Sentence: {buffer[:20]}...")
                    audio_b64 = await generate_tts(buffer)
                    if audio_b64:
                        await websocket.send_json({"type": "audio", "data": audio_b64})
                    buffer = "" # Reset buffer
            
            # 3. Handle Finish
            if event.get("status") == "finished":
                full_final_res = event.get("result")
                # Flush remaining buffer
                if buffer.strip():
                     audio_b64 = await generate_tts(buffer)
                     if audio_b64:
                        await websocket.send_json({"type": "audio", "data": audio_b64})

        # [Save Logic] (Redis + File)
        await websocket.send_json({"type": "finished", "data": full_final_res})
        
        if full_final_res:
             try:
                answer = full_final_res.get("answer", "")
                site_hint = full_final_res.get("site")
                if answer:
                    from datetime import datetime
                    from uuid import uuid4
                    import os
                    
                    new_entry = {
                        "id": str(uuid4()),
                        "user_id": data.get("user_id", "anonymous"),
                        "level_id": data.get("level_id", 1),
                        "character_id": data.get("character_id", 1),
                        "message": user_input,
                        "response": answer,
                        # "audio_base64": ... (omit for DB size)
                        "context": {
                             "characterId": data.get("character_id", 1),
                             "intent": full_final_res.get("intent"),
                             "site": site_hint
                        },
                        "created_at": datetime.utcnow().isoformat() + "Z",
                        "user_input": user_input, "generated_answer": answer, "site": site_hint
                    }
                    
                    history.append(new_entry)
                    if redis_key:
                        await app.state.redis.set(redis_key, json.dumps(history[-20:], ensure_ascii=False))
                    
                    # File Log
                    if ENABLE_FILE_LOGGING:
                        log_file = "chat_logs.json"
                        current_logs = []
                        if os.path.exists(log_file):
                            with open(log_file, "r", encoding="utf-8") as f:
                                 try: 
                                     current_logs = json.load(f)
                                     if not isinstance(current_logs, list): current_logs = []
                                 except: current_logs = []
                        current_logs.append(new_entry)
                        with open(log_file, "w", encoding="utf-8") as f:
                            json.dump(current_logs, f, ensure_ascii=False, indent=2)
             except Exception as e:
                logger.error(f"WS Save Error: {e}")

    except WebSocketDisconnect:
        logger.info("WebSocket disconnected")
    except Exception as e:
        logger.error(f"WS Error: {e}")
        try:
            await websocket.send_json({"type": "error", "message": str(e)})
        except: pass