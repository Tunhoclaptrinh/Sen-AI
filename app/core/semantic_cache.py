"""
SemanticCache: Cache cÃ¢u tráº£ lá»i dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a (cosine similarity).
- LÆ°u trá»¯: MongoDB collection `query_cache`
- Embedding: local SentenceTransformer (paraphrase-multilingual-MiniLM-L12-v2)
- Lookup: cosine similarity trong Python (khÃ´ng cáº§n Atlas Vector Search Index má»›i)
- Threshold: 0.92 (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)
"""

import logging
import time
import numpy as np
from typing import Optional, Any, Dict
from pymongo import MongoClient

logger = logging.getLogger("uvicorn")

SIMILARITY_THRESHOLD = 0.92   # NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng Ä‘á»ƒ coi lÃ  "cÃ¹ng cÃ¢u há»i"
MAX_CACHE_ENTRIES   = 500     # Giá»›i háº¡n sá»‘ entry Ä‘á»ƒ khÃ´ng load quÃ¡ nhiá»u
DEFAULT_TTL         = 3600    # 1 tiáº¿ng (giÃ¢y)


class SemanticCache:
    """
    Cache ngá»¯ nghÄ©a: thay vÃ¬ khá»›p tá»«ng chá»¯, so sÃ¡nh embedding cosine similarity.
    VÃ­ dá»¥:
        "LÃ½ ThÃ¡i Tá»• lÃ  ai?"  â‰ˆ  "Ai lÃ  LÃ½ ThÃ¡i Tá»•?"  â†’ HIT
        "Cho tÃ´i biáº¿t vá» LÃ½ ThÃ¡i Tá»•"                  â†’ HIT (náº¿u > 0.92)
    """

    def __init__(self, db, embedder):
        """
        Args:
            db: pymongo Database object (v_db.db)
            embedder: SentenceTransformer instance
        """
        self.col = db["query_cache"]
        self.embedder = embedder
        self._ensure_indexes()

    def _ensure_indexes(self):
        try:
            self.col.create_index("expires_at", expireAfterSeconds=0)  # TTL index
            self.col.create_index("intent")
            logger.info("âœ… [SemanticCache] Indexes OK.")
        except Exception as e:
            logger.warning(f"âš ï¸ [SemanticCache] Index warning: {e}")

    def _embed(self, text: str) -> np.ndarray:
        """Embed text thÃ nh vector numpy."""
        vec = self.embedder.encode(text, normalize_embeddings=True)
        return np.array(vec, dtype=np.float32)

    def _cosine(self, a: np.ndarray, b: np.ndarray) -> float:
        """Cosine similarity â€” Ä‘Ã£ normalize_embeddings=True nÃªn chá»‰ cáº§n dot product."""
        return float(np.dot(a, b))

    # â”€â”€â”€ PUBLIC API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get(self, query: str, intent_filter: str = "heritage") -> Optional[Dict]:
        """
        TÃ¬m response tÆ°Æ¡ng Ä‘á»“ng trong cache.
        Returns: dict response náº¿u tÃ¬m tháº¥y, None náº¿u khÃ´ng.
        """
        try:
            query_vec = self._embed(query)

            # Load MAX_CACHE_ENTRIES entries gáº§n nháº¥t (chá»‰ intent cáº§n thiáº¿t)
            entries = list(
                self.col.find(
                    {"intent": intent_filter},
                    {"query_embedding": 1, "response": 1, "_id": 0}
                ).sort("_id", -1).limit(MAX_CACHE_ENTRIES)
            )

            if not entries:
                return None

            best_score = 0.0
            best_entry = None

            for entry in entries:
                stored_vec = np.array(entry["query_embedding"], dtype=np.float32)
                score = self._cosine(query_vec, stored_vec)
                if score > best_score:
                    best_score = score
                    best_entry = entry

            if best_score >= SIMILARITY_THRESHOLD and best_entry:
                logger.info(f"   ðŸŽ¯ [SemanticCache] HIT (similarity={best_score:.3f})")
                return best_entry["response"]

            logger.info(f"   ðŸ’¨ [SemanticCache] MISS (best={best_score:.3f} < {SIMILARITY_THRESHOLD})")
            return None

        except Exception as e:
            logger.warning(f"âš ï¸ [SemanticCache] get() error: {e}")
            return None

    def set(self, query: str, response: Dict, intent: str = "heritage", ttl: int = DEFAULT_TTL):
        """
        LÆ°u response vÃ o cache.
        Args:
            query: cÃ¢u há»i gá»‘c (Ä‘Ã£ normalize)
            response: dict káº¿t quáº£ tá»« workflow
            intent: loáº¡i intent Ä‘á»ƒ filter khi lookup
            ttl: thá»i gian sá»‘ng tÃ­nh báº±ng giÃ¢y
        """
        try:
            query_vec = self._embed(query)
            expires_at = time.time() + ttl

            self.col.insert_one({
                "query": query,
                "query_embedding": query_vec.tolist(),
                "response": response,
                "intent": intent,
                "expires_at": expires_at,
            })
            logger.info(f"   ðŸ’¾ [SemanticCache] Saved (TTL={ttl}s)")

        except Exception as e:
            logger.warning(f"âš ï¸ [SemanticCache] set() error: {e}")

    def delete_expired(self):
        """XÃ³a thá»§ cÃ´ng cÃ¡c entry háº¿t háº¡n (MongoDB TTL index sáº½ tá»± xÃ³a, nhÆ°ng cÃ³ thá»ƒ gá»i thá»§ cÃ´ng)."""
        try:
            result = self.col.delete_many({"expires_at": {"$lt": time.time()}})
            logger.info(f"ðŸ§¹ [SemanticCache] Deleted {result.deleted_count} expired entries")
        except Exception as e:
            logger.warning(f"âš ï¸ [SemanticCache] delete_expired error: {e}")

    def count(self) -> int:
        return self.col.count_documents({})
