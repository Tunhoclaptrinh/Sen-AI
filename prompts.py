import json
import os
import logging
from data_manager import get_heritage_config
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

# File c·∫•u h√¨nh Prompts
PROMPT_FILE = os.path.join(os.path.dirname(__file__), "data", "prompts.json")

def load_prompts():
    """Load prompts from JSON file."""
    if not os.path.exists(PROMPT_FILE):
        return {}
    try:
        with open(PROMPT_FILE, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            
        # üîß NEW: T·ª± ƒë·ªông n·ªëi list th√†nh string ƒë·ªÉ file JSON d·ªÖ ƒë·ªçc h∆°n
        processed_data = {}
        for key, value in raw_data.items():
            if isinstance(value, list):
                processed_data[key] = "\n".join(value)
            else:
                processed_data[key] = value
        
        return processed_data
    except Exception as e:
        logger.error(f"‚ùå Error loading prompts: {e}")
        return {}

# Initial Load
_PROMPTS = load_prompts()

def get_bot_name():
    return os.getenv("BOT_NAME", "Sen")

def get_sen_persona():
    global _PROMPTS
    raw = _PROMPTS.get("sen_persona", "B·∫°n l√† {bot_name} - tr·ª£ l√Ω ·∫£o AI.")
    return raw.replace("{bot_name}", get_bot_name())

def get_planner_prompt(candidate_sites, hint_str=""):
    """
    Construct dynamic planner prompt using stored template via Dynamic In-Context Learning.
    candidate_sites: List of site dicts (filtered by semantic search).
    hint_str: Optional hints.
    """
    global _PROMPTS
    base_prompt = _PROMPTS.get("planner_prompt", "")
    
    # Inject Bot Name
    base_prompt = base_prompt.replace("{bot_name}", get_bot_name())
    
    # N·∫øu kh√¥ng c√≥ file config, d√πng default hardcode ƒë·ªÉ tr√°nh crash
    if not base_prompt:
        base_prompt = """B·∫°n l√† Nh·∫°c tr∆∞·ªüng ƒëi·ªÅu ph·ªëi Sen NPC. Tr·∫£ v·ªÅ JSON intent: heritage, realtime, chitchat, out_of_scope."""

    # Chu·∫©n b·ªã context danh s√°ch site
    if not candidate_sites: 
        # Fallback l·∫•y full list n·∫øu ch∆∞a filter
        full_config = get_heritage_config()
        candidate_sites = list(full_config.values())

    site_info_str = "\n".join([f"- {v['key']}: {v['name']}\n  M√¥ t·∫£: {v.get('context_description', '')}" for v in candidate_sites])
    site_keys = [v['key'] for v in candidate_sites]

    # Inject dynamic data
    dynamic_part = f"""
DANH S√ÅCH DI T√çCH H·ª¢P L·ªÜ (Context):
{site_info_str}

DANH S√ÅCH KEY: {site_keys} ho·∫∑c null.

‚≠ê S·ª¨ D·ª§NG SITE HINT:
{hint_str}

‚ö†Ô∏è QUY T·∫ÆC ƒê·∫∂C BI·ªÜT:
- N·∫øu ng∆∞·ªùi d√πng h·ªèi g·ª£i √Ω ƒë·ªãa ƒëi·ªÉm, h·ªèi chung chung (VD: "ƒëi ƒë√¢u ch∆°i", "gi·ªõi thi·ªáu ch·ªó kh√°c", "kh√°m ph√° g√¨", "c√≤n ch·ªó n√†o kh√¥ng") -> Intent: "chitchat" (ƒë·ªÉ AI t·ª± g·ª£i √Ω) ho·∫∑c "heritage" (site: null).
- KH√îNG tr·∫£ v·ªÅ "out_of_scope" n·∫øu c√¢u h·ªèi li√™n quan ƒë·∫øn du l·ªãch/tham quan/l·ªãch s·ª≠, k·ªÉ c·∫£ khi kh√¥ng kh·ªõp site key n√†o.
"""
    
    return base_prompt + "\n" + dynamic_part



def reload_prompts():
    global _PROMPTS
    _PROMPTS = load_prompts()
    logger.info("üîÑ Prompts reloaded from JSON.")

def get_verifier_prompt():
    global _PROMPTS
    return _PROMPTS.get("verifier_prompt", """
B·∫°n l√† Tr∆∞·ªüng ban Ki·ªÉm duy·ªát N·ªôi dung c·ªßa Sen NPC.
Nhi·ªám v·ª•: ƒê√°nh gi√° c√¢u tr·∫£ l·ªùi c·ªßa Sen c√≥ an to√†n, ƒë√∫ng tr·ªçng t√¢m v√† kh√¥ng b·ªãa ƒë·∫∑t hay kh√¥ng.
N·∫øu c√¢u tr·∫£ l·ªùi t·ªët, tr·∫£ v·ªÅ {"valid": true}.
N·∫øu n·ªôi dung ƒë·ªôc h·∫°i, sai l·ªách nghi√™m tr·ªçng, ho·∫∑c b·ªãa ƒë·∫∑t (hallucination) khi kh√¥ng c√≥ context, tr·∫£ v·ªÅ {"valid": false, "reason": "..."}.
""")

def get_contextualize_prompt():
    global _PROMPTS
    return _PROMPTS.get("contextualize_prompt", """
B·∫°n l√† chuy√™n gia ng√¥n ng·ªØ h·ªçc, nhi·ªám v·ª• l√† VI·∫æT L·∫†I (Rewrite) c√¢u n√≥i c·ªßa ng∆∞·ªùi d√πng th√†nh m·ªôt c√¢u ƒë·∫ßy ƒë·ªß ng·ªØ nghƒ©a, d·ª±a tr√™n L·ªãch s·ª≠ h·ªôi tho·∫°i.

QUY T·∫ÆC QUAN TR·ªåNG:
1. Ph√¢n t√≠ch c√¢u cu·ªëi c√πng c·ªßa AI trong l·ªãch s·ª≠:
   - N·∫øu AI ƒëang h·ªèi/m·ªùi m·ªçc (V√≠ d·ª•: "B·∫°n c√≥ mu·ªën g·ª£i √Ω ƒë·ªãa ƒëi·ªÉm kh√°c kh√¥ng?", "T√¥i k·ªÉ ti·∫øp nh√©?").
   - V√† ng∆∞·ªùi d√πng tr·∫£ l·ªùi ng·∫Øn (V√≠ d·ª•: "C√≥", "Kh√¥ng", "Ok", "T√¥i kh√¥ng mu·ªën", "Sao c≈©ng ƒë∆∞·ª£c").
   -> H√ÉY VI·∫æT L·∫†I th√†nh h√†nh ƒë·ªông c·ª• th·ªÉ m√† ng∆∞·ªùi d√πng mu·ªën.
   
2. V√≠ d·ª• minh h·ªça:
   - AI: "...C·∫ßn m√¨nh g·ª£i √Ω ch·ªó ƒÉn ngon kh√¥ng?" -> User: "C√≥" => Rewrite: "H√£y g·ª£i √Ω cho t√¥i qu√°n ƒÉn ngon."
   - AI: "...Mu·ªën nghe l·ªãch s·ª≠ ti·∫øp kh√¥ng?" -> User: "Th√¥i" => Rewrite: "T√¥i kh√¥ng mu·ªën nghe l·ªãch s·ª≠ n·ªØa, h√£y chuy·ªÉn ch·ªß ƒë·ªÅ."
   - AI: "...Ho√†ng Th√†nh ƒë√≥ng c·ª≠a r·ªìi." -> User: "Th·∫ø ƒëi ƒë√¢u gi·ªù?" => Rewrite: "G·ª£i √Ω ƒë·ªãa ƒëi·ªÉm tham quan kh√°c thay th·∫ø cho Ho√†ng Th√†nh ThƒÉng Long."

3. N·∫øu c√¢u n√≥i ƒë√£ ƒë·ªß √Ω ho·∫∑c l√† ch·ªß ƒë·ªÅ m·ªõi -> Gi·ªØ nguy√™n.

OUTPUT: Ch·ªâ tr·∫£ v·ªÅ c√¢u ƒë√£ vi·∫øt l·∫°i, kh√¥ng gi·∫£i th√≠ch th√™m.
""")

# Backward compatibility & Export
SEN_CHARACTER_PROMPT = get_sen_persona()
PLANNER_SYSTEM_PROMPT = "Use get_planner_prompt() function instead."
VERIFIER_SYSTEM_PROMPT = get_verifier_prompt()